{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import pandas as pd\n",
    "    import json\n",
    "    import re\n",
    "    import spacy\n",
    "    import nltk\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from rank_bm25 import BM25Okapi\n",
    "    from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载声明数据\n",
    "claim_file_path = \"data/train-claims.json\"\n",
    "with open(claim_file_path, \"r\") as file:\n",
    "    claims_data = json.load(file)\n",
    "\n",
    "# 加载证据数据\n",
    "evidence_file_path = \"data/evidence.json\"\n",
    "with open(evidence_file_path, \"r\") as file:\n",
    "    evidence_data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换声明数据为DataFrame\n",
    "claims = []\n",
    "for claim_id, details in claims_data.items():\n",
    "    claims.append({'claim_id': claim_id, **details})\n",
    "claims_df = pd.DataFrame(claims)\n",
    "\n",
    "# 转换证据数据为DataFrame\n",
    "evidences = []\n",
    "for ev_id, text in evidence_data.items():\n",
    "    evidences.append({'evidence_id': ev_id, 'text': text})\n",
    "evidence_df = pd.DataFrame(evidences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载Spacy英语模型\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# 创建NER映射表并进行实体提取\n",
    "ner_map = defaultdict(list)\n",
    "\n",
    "for index, row in evidence_df.iterrows():\n",
    "    doc = nlp(row['text'])\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append(ent.text)\n",
    "    ner_map[row['evidence_id']] = entities  # 保存每个证据的实体列表\n",
    "\n",
    "# 将实体信息添加到DataFrame\n",
    "evidence_df['entities'] = evidence_df['evidence_id'].map(ner_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text(text, entities):\n",
    "    \"\"\"保留英文单词和特定模式（如化学符号、数字与字母的组合等），同时保留已识别的实体\"\"\"\n",
    "    pattern = re.compile(r'\\b[a-zA-Z0-9]+\\b')\n",
    "    tokens = word_tokenize(text)\n",
    "    entities = set(entities)  # 将实体列表转换为集合以快速检查\n",
    "    filtered_tokens = [token for token in tokens if pattern.match(token) or token in entities]\n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "# 应用文本过滤，同时考虑实体\n",
    "claims_df['claim_text'] = claims_df.apply(lambda row: filter_text(row['claim_text'], row.get('entities', [])), axis=1)\n",
    "evidence_df['text'] = evidence_df.apply(lambda row: filter_text(row['text'], row['entities']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_entities(text, entities):\n",
    "    \"\"\"使用Spacy进行分词，并对实体进行加权处理\"\"\"\n",
    "    doc = nlp(text)\n",
    "    words = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "    # 增加实体的出现次数\n",
    "    words.extend([entity.lower() for entity in entities for _ in range(3)])  # 实体权重增加，出现3次\n",
    "    return words\n",
    "\n",
    "# 应用分词并考虑实体\n",
    "evidence_df['tokens'] = evidence_df.apply(lambda row: tokenize_with_entities(row['text'], row['entities']), axis=1)\n",
    "bm25 = BM25Okapi(evidence_df['tokens'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查evidence_df['tokens']列是否不存在大写字母\n",
    "def has_upper(tokens):\n",
    "    for token in tokens:\n",
    "        if token.isupper():\n",
    "            return True\n",
    "    return False\n",
    " \n",
    "\n",
    "# 检查是否存在大写字母的证据\n",
    "evidence_df['has_upper'] = evidence_df['tokens'].apply(has_upper)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [evidence_id, text, entities, tokens, has_upper]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(evidence_df[evidence_df['has_upper'] == True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text(text):\n",
    "    \"\"\"保留英文单词和特定模式（如化学符号、数字与字母的组合等）\"\"\"\n",
    "    pattern = re.compile(r'\\b[a-zA-Z0-9]+\\b')  # 识别字母和数字的组合\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [token for token in tokens if pattern.match(token)]\n",
    "    return \" \".join(filtered_tokens)\n",
    "# 应用文本过滤函数到正确的列\n",
    "dev_claims_df['claim_text'] = dev_claims_df['claim_text'].apply(filter_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载开发集数据\n",
    "dev_claim_file_path = \"data/dev-claims.json\"\n",
    "with open(dev_claim_file_path, \"r\") as file:\n",
    "    dev_claims_data = json.load(file)\n",
    "\n",
    "dev_claims = []\n",
    "for claim_id, details in dev_claims_data.items():\n",
    "    dev_claims.append({'claim_id': claim_id, **details})\n",
    "dev_claims_df = pd.DataFrame(dev_claims)\n",
    "\n",
    "# 应用文本过滤函数到正确的列\n",
    "dev_claims_df['claim_text'] = dev_claims_df['claim_text'].apply(filter_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 保存ner_map\n",
    "with open('ner_map.pkl', 'wb') as f:\n",
    "    pickle.dump(ner_map, f)\n",
    "# 保存处理后的DataFrame\n",
    "claims_df.to_pickle(\"processed_claims_df.pkl\")\n",
    "evidence_df.to_pickle(\"processed_evidence_df.pkl\")\n",
    "# 保存令牌列表\n",
    "with open('tokens.pkl', 'wb') as f:\n",
    "    pickle.dump(evidence_df['tokens'].tolist(), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取测试集数据\n",
    "test_claim_file_path = \"data/test-claims-unlabelled.json\"\n",
    "\n",
    "# 处理测试集数据\n",
    "with open(test_claim_file_path, \"r\") as file:\n",
    "    test_claims_data = json.load(file)\n",
    "\n",
    "test_claims = []\n",
    "for claim_id, details in test_claims_data.items():\n",
    "    test_claims.append({'claim_id': claim_id, **details})\n",
    "test_claims_df = pd.DataFrame(test_claims)\n",
    "\n",
    "# 应用文本过滤函数到正确的列\n",
    "test_claims_df['claim_text'] = test_claims_df['claim_text'].apply(filter_text)\n",
    "# 保存测试集DataFrame\n",
    "test_claims_df.to_pickle(\"processed_test_claims_df.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2973523421588595\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_evidence(claim_text, entities, top_n=20):\n",
    "    # 为声明文本和相关实体构建查询令牌\n",
    "    claim_tokens = tokenize_with_entities(claim_text, entities)\n",
    "    scores = bm25.get_scores(claim_tokens)\n",
    "    top_indexes = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_n]\n",
    "    return [evidence_df.iloc[i]['evidence_id'] for i in top_indexes]\n",
    "\n",
    "# 检索证据并计算准确率\n",
    "correct_hits = 0\n",
    "total_evidences = 0\n",
    "\n",
    "for index, row in dev_claims_df.iterrows():\n",
    "    predicted_evidences = get_top_n_evidence(row['claim_text'], row.get('entities', []))\n",
    "    actual_evidences = row['evidences']\n",
    "    correct_hits += len(set(predicted_evidences) & set(actual_evidences))\n",
    "    total_evidences += len(actual_evidences)\n",
    "\n",
    "accuracy = correct_hits / total_evidences\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3890020366598778\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_evidence(claim_text, entities, top_n=40):\n",
    "    claim_tokens = tokenize_with_entities(claim_text, entities)\n",
    "    scores = bm25.get_scores(claim_tokens)\n",
    "    top_indexes = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_n]\n",
    "    return [evidence_df.iloc[i]['evidence_id'] for i in top_indexes]\n",
    "predicted_results = {}\n",
    "correct_hits = 0\n",
    "total_evidences = 0\n",
    "\n",
    "for index, row in dev_claims_df.iterrows():\n",
    "    predicted_evidences = get_top_n_evidence(row['claim_text'], row.get('entities', []))\n",
    "    actual_evidences = row['evidences']\n",
    "    correct_hits += len(set(predicted_evidences) & set(actual_evidences))\n",
    "    total_evidences += len(actual_evidences)\n",
    "    predicted_results[row['claim_id']] = {\n",
    "        \"claim_text\": row['claim_text'],\n",
    "        \"evidences\": predicted_evidences\n",
    "    }\n",
    "\n",
    "accuracy = correct_hits / total_evidences\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "import json\n",
    "\n",
    "# 保存预测结果到JSON文件\n",
    "with open('data/predicted_evidences_dev.json', 'w') as f:\n",
    "    json.dump(predicted_results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42973523421588594\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_evidence(claim_text, entities, top_n=60):\n",
    "    claim_tokens = tokenize_with_entities(claim_text, entities)\n",
    "    scores = bm25.get_scores(claim_tokens)\n",
    "    top_indexes = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_n]\n",
    "    return [evidence_df.iloc[i]['evidence_id'] for i in top_indexes]\n",
    "predicted_results = {}\n",
    "correct_hits = 0\n",
    "total_evidences = 0\n",
    "\n",
    "for index, row in dev_claims_df.iterrows():\n",
    "    predicted_evidences = get_top_n_evidence(row['claim_text'], row.get('entities', []))\n",
    "    actual_evidences = row['evidences']\n",
    "    correct_hits += len(set(predicted_evidences) & set(actual_evidences))\n",
    "    total_evidences += len(actual_evidences)\n",
    "    predicted_results[row['claim_id']] = {\n",
    "        \"claim_text\": row['claim_text'],\n",
    "        \"evidences\": predicted_evidences\n",
    "    }\n",
    "\n",
    "accuracy = correct_hits / total_evidences\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "import json\n",
    "\n",
    "# 保存预测结果到JSON文件\n",
    "with open('data/predicted_evidences_dev_60.json', 'w') as f:\n",
    "    json.dump(predicted_results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4623217922606925\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_evidence(claim_text, entities, top_n=80):\n",
    "    claim_tokens = tokenize_with_entities(claim_text, entities)\n",
    "    scores = bm25.get_scores(claim_tokens)\n",
    "    top_indexes = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_n]\n",
    "    return [evidence_df.iloc[i]['evidence_id'] for i in top_indexes]\n",
    "predicted_results = {}\n",
    "correct_hits = 0\n",
    "total_evidences = 0\n",
    "\n",
    "for index, row in dev_claims_df.iterrows():\n",
    "    predicted_evidences = get_top_n_evidence(row['claim_text'], row.get('entities', []))\n",
    "    actual_evidences = row['evidences']\n",
    "    correct_hits += len(set(predicted_evidences) & set(actual_evidences))\n",
    "    total_evidences += len(actual_evidences)\n",
    "    predicted_results[row['claim_id']] = {\n",
    "        \"claim_text\": row['claim_text'],\n",
    "        \"evidences\": predicted_evidences\n",
    "    }\n",
    "\n",
    "accuracy = correct_hits / total_evidences\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "import json\n",
    "\n",
    "# 保存预测结果到JSON文件\n",
    "with open('data/predicted_evidences_dev_80.json', 'w') as f:\n",
    "    json.dump(predicted_results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4908350305498982\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_evidence(claim_text, entities, top_n=100):\n",
    "    claim_tokens = tokenize_with_entities(claim_text, entities)\n",
    "    scores = bm25.get_scores(claim_tokens)\n",
    "    top_indexes = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_n]\n",
    "    return [evidence_df.iloc[i]['evidence_id'] for i in top_indexes]\n",
    "predicted_results = {}\n",
    "correct_hits = 0\n",
    "total_evidences = 0\n",
    "\n",
    "for index, row in dev_claims_df.iterrows():\n",
    "    predicted_evidences = get_top_n_evidence(row['claim_text'], row.get('entities', []))\n",
    "    actual_evidences = row['evidences']\n",
    "    correct_hits += len(set(predicted_evidences) & set(actual_evidences))\n",
    "    total_evidences += len(actual_evidences)\n",
    "    predicted_results[row['claim_id']] = {\n",
    "        \"claim_text\": row['claim_text'],\n",
    "        \"evidences\": predicted_evidences\n",
    "    }\n",
    "\n",
    "accuracy = correct_hits / total_evidences\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "import json\n",
    "\n",
    "# 保存预测结果到JSON文件\n",
    "with open('data/predicted_evidences_dev_100.json', 'w') as f:\n",
    "    json.dump(predicted_results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5193482688391039\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_evidence(claim_text, entities, top_n=150):\n",
    "    claim_tokens = tokenize_with_entities(claim_text, entities)\n",
    "    scores = bm25.get_scores(claim_tokens)\n",
    "    top_indexes = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_n]\n",
    "    return [evidence_df.iloc[i]['evidence_id'] for i in top_indexes]\n",
    "predicted_results = {}\n",
    "correct_hits = 0\n",
    "total_evidences = 0\n",
    "\n",
    "for index, row in dev_claims_df.iterrows():\n",
    "    predicted_evidences = get_top_n_evidence(row['claim_text'], row.get('entities', []))\n",
    "    actual_evidences = row['evidences']\n",
    "    correct_hits += len(set(predicted_evidences) & set(actual_evidences))\n",
    "    total_evidences += len(actual_evidences)\n",
    "    predicted_results[row['claim_id']] = {\n",
    "        \"claim_text\": row['claim_text'],\n",
    "        \"evidences\": predicted_evidences\n",
    "    }\n",
    "\n",
    "accuracy = correct_hits / total_evidences\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "import json\n",
    "\n",
    "# 保存预测结果到JSON文件\n",
    "with open('data/predicted_evidences_dev_150.json', 'w') as f:\n",
    "    json.dump(predicted_results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5560081466395111\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_evidence(claim_text, entities, top_n=200):\n",
    "    claim_tokens = tokenize_with_entities(claim_text, entities)\n",
    "    scores = bm25.get_scores(claim_tokens)\n",
    "    top_indexes = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_n]\n",
    "    return [evidence_df.iloc[i]['evidence_id'] for i in top_indexes]\n",
    "predicted_results = {}\n",
    "correct_hits = 0\n",
    "total_evidences = 0\n",
    "\n",
    "for index, row in dev_claims_df.iterrows():\n",
    "    predicted_evidences = get_top_n_evidence(row['claim_text'], row.get('entities', []))\n",
    "    actual_evidences = row['evidences']\n",
    "    correct_hits += len(set(predicted_evidences) & set(actual_evidences))\n",
    "    total_evidences += len(actual_evidences)\n",
    "    predicted_results[row['claim_id']] = {\n",
    "        \"claim_text\": row['claim_text'],\n",
    "        \"evidences\": predicted_evidences\n",
    "    }\n",
    "\n",
    "accuracy = correct_hits / total_evidences\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "import json\n",
    "\n",
    "# 保存预测结果到JSON文件\n",
    "with open('data/predicted_evidences_dev_200.json', 'w') as f:\n",
    "    json.dump(predicted_results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6476578411405295\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_evidence(claim_text, entities, top_n=500):\n",
    "    claim_tokens = tokenize_with_entities(claim_text, entities)\n",
    "    scores = bm25.get_scores(claim_tokens)\n",
    "    top_indexes = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_n]\n",
    "    return [evidence_df.iloc[i]['evidence_id'] for i in top_indexes]\n",
    "predicted_results = {}\n",
    "correct_hits = 0\n",
    "total_evidences = 0\n",
    "\n",
    "for index, row in dev_claims_df.iterrows():\n",
    "    predicted_evidences = get_top_n_evidence(row['claim_text'], row.get('entities', []))\n",
    "    actual_evidences = row['evidences']\n",
    "    correct_hits += len(set(predicted_evidences) & set(actual_evidences))\n",
    "    total_evidences += len(actual_evidences)\n",
    "    predicted_results[row['claim_id']] = {\n",
    "        \"claim_text\": row['claim_text'],\n",
    "        \"evidences\": predicted_evidences\n",
    "    }\n",
    "\n",
    "accuracy = correct_hits / total_evidences\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "import json\n",
    "\n",
    "# 保存预测结果到JSON文件\n",
    "with open('data/predicted_evidences_dev_500.json', 'w') as f:\n",
    "    json.dump(predicted_results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.15478615071283094\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_evidence(claim_text, entities, top_n=5):\n",
    "    claim_tokens = tokenize_with_entities(claim_text, entities)\n",
    "    scores = bm25.get_scores(claim_tokens)\n",
    "    top_indexes = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_n]\n",
    "    return [evidence_df.iloc[i]['evidence_id'] for i in top_indexes]\n",
    "predicted_results = {}\n",
    "correct_hits = 0\n",
    "total_evidences = 0\n",
    "\n",
    "for index, row in dev_claims_df.iterrows():\n",
    "    predicted_evidences = get_top_n_evidence(row['claim_text'], row.get('entities', []))\n",
    "    actual_evidences = row['evidences']\n",
    "    correct_hits += len(set(predicted_evidences) & set(actual_evidences))\n",
    "    total_evidences += len(actual_evidences)\n",
    "    predicted_results[row['claim_id']] = {\n",
    "        \"claim_text\": row['claim_text'],\n",
    "        \"evidences\": predicted_evidences\n",
    "    }\n",
    "\n",
    "accuracy = correct_hits / total_evidences\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "import json\n",
    "\n",
    "# 保存预测结果到JSON文件\n",
    "with open('data/predicted_evidences_dev_5.json', 'w') as f:\n",
    "    json.dump(predicted_results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1384928716904277\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_evidence(claim_text, entities, top_n=4):\n",
    "    claim_tokens = tokenize_with_entities(claim_text, entities)\n",
    "    scores = bm25.get_scores(claim_tokens)\n",
    "    top_indexes = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_n]\n",
    "    return [evidence_df.iloc[i]['evidence_id'] for i in top_indexes]\n",
    "predicted_results = {}\n",
    "correct_hits = 0\n",
    "total_evidences = 0\n",
    "\n",
    "for index, row in dev_claims_df.iterrows():\n",
    "    predicted_evidences = get_top_n_evidence(row['claim_text'], row.get('entities', []))\n",
    "    actual_evidences = row['evidences']\n",
    "    correct_hits += len(set(predicted_evidences) & set(actual_evidences))\n",
    "    total_evidences += len(actual_evidences)\n",
    "    predicted_results[row['claim_id']] = {\n",
    "        \"claim_text\": row['claim_text'],\n",
    "        \"evidences\": predicted_evidences\n",
    "    }\n",
    "\n",
    "accuracy = correct_hits / total_evidences\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "import json\n",
    "\n",
    "# 保存预测结果到JSON文件\n",
    "with open('data/predicted_evidences_dev_4.json', 'w') as f:\n",
    "    json.dump(predicted_results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.04684317718940937\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_evidence(claim_text, entities, top_n=1):\n",
    "    claim_tokens = tokenize_with_entities(claim_text, entities)\n",
    "    scores = bm25.get_scores(claim_tokens)\n",
    "    top_indexes = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_n]\n",
    "    return [evidence_df.iloc[i]['evidence_id'] for i in top_indexes]\n",
    "predicted_results = {}\n",
    "correct_hits = 0\n",
    "total_evidences = 0\n",
    "\n",
    "for index, row in dev_claims_df.iterrows():\n",
    "    predicted_evidences = get_top_n_evidence(row['claim_text'], row.get('entities', []))\n",
    "    actual_evidences = row['evidences']\n",
    "    correct_hits += len(set(predicted_evidences) & set(actual_evidences))\n",
    "    total_evidences += len(actual_evidences)\n",
    "    predicted_results[row['claim_id']] = {\n",
    "        \"claim_text\": row['claim_text'],\n",
    "        \"evidences\": predicted_evidences\n",
    "    }\n",
    "\n",
    "accuracy = correct_hits / total_evidences\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "import json\n",
    "\n",
    "# 保存预测结果到JSON文件\n",
    "with open('data/predicted_evidences_dev_1.json', 'w') as f:\n",
    "    json.dump(predicted_results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_100_evidence(claim_text, entities):\n",
    "    # 为声明文本和相关实体构建查询令牌\n",
    "    claim_tokens = tokenize_with_entities(claim_text, entities)\n",
    "    scores = bm25.get_scores(claim_tokens)\n",
    "    top_indexes = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:100]\n",
    "    return [evidence_df.iloc[i]['evidence_id'] for i in top_indexes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     claim_id       evidence_id  label\n",
      "0  claim-1937   evidence-442946      1\n",
      "1  claim-1937    evidence-55991      0\n",
      "2  claim-1937  evidence-1167485      0\n",
      "3  claim-1937   evidence-180631      0\n",
      "4  claim-1937    evidence-66273      0\n"
     ]
    }
   ],
   "source": [
    "# 创建机器学习训练数据集\n",
    "ml_training_data = []\n",
    "\n",
    "for index, row in claims_df.iterrows():\n",
    "    predicted_evidences = get_top_100_evidence(row['claim_text'], row.get('entities', []))\n",
    "    actual_evidences = row['evidences']\n",
    "    true_evidences = [ev for ev in predicted_evidences if ev in actual_evidences]\n",
    "    false_evidences = [ev for ev in predicted_evidences if ev not in actual_evidences][:5 * len(true_evidences)]\n",
    "\n",
    "    # 将每个真实证据作为一个正样本\n",
    "    for ev in true_evidences:\n",
    "        ml_training_data.append({\n",
    "            'claim_id': row['claim_id'],\n",
    "            'evidence_id': ev,\n",
    "            'label': 1  # 正样本\n",
    "        })\n",
    "\n",
    "    # 将选定的假证据作为负样本\n",
    "    for ev in false_evidences:\n",
    "        ml_training_data.append({\n",
    "            'claim_id': row['claim_id'],\n",
    "            'evidence_id': ev,\n",
    "            'label': 0  # 负样本\n",
    "        })\n",
    "\n",
    "# 转换为DataFrame\n",
    "ml_training_df = pd.DataFrame(ml_training_data)\n",
    "print(ml_training_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 创建机器学习训练数据集\n",
    "ml_training_data2 = []\n",
    "\n",
    "for index, row in claims_df.iterrows():\n",
    "    predicted_evidences = get_top_100_evidence(row['claim_text'], row.get('entities', []))\n",
    "    actual_evidences = row['evidences']\n",
    "    true_evidences = [ev for ev in predicted_evidences if ev in actual_evidences]\n",
    "    false_evidences = [ev for ev in predicted_evidences if ev not in actual_evidences][:1 * len(true_evidences)]\n",
    "\n",
    "    # 将每个真实证据作为一个正样本\n",
    "    for ev in true_evidences:\n",
    "        ml_training_data.append({\n",
    "            'claim_id': row['claim_id'],\n",
    "            'evidence_id': ev,\n",
    "            'label': 1  # 正样本\n",
    "        })\n",
    "\n",
    "    # 将选定的假证据作为负样本\n",
    "    for ev in false_evidences:\n",
    "        ml_training_data.append({\n",
    "            'claim_id': row['claim_id'],\n",
    "            'evidence_id': ev,\n",
    "            'label': 0  # 负样本\n",
    "        })\n",
    "\n",
    "# 转换为DataFrame\n",
    "ml_training_df2 = pd.DataFrame(ml_training_data2)\n",
    "print(ml_training_df2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     claim_id       evidence_id  label  \\\n",
      "0  claim-1937   evidence-442946      1   \n",
      "1  claim-1937    evidence-55991      0   \n",
      "2  claim-1937  evidence-1167485      0   \n",
      "3  claim-1937   evidence-180631      0   \n",
      "4  claim-1937    evidence-66273      0   \n",
      "\n",
      "                                          claim_text  \\\n",
      "0  Not only is there no scientific evidence that ...   \n",
      "1  Not only is there no scientific evidence that ...   \n",
      "2  Not only is there no scientific evidence that ...   \n",
      "3  Not only is there no scientific evidence that ...   \n",
      "4  Not only is there no scientific evidence that ...   \n",
      "\n",
      "                                       evidence_text  \n",
      "0  At very high concentrations 100 times atmosphe...  \n",
      "1  On July 21 2011 while a guest on the show he s...  \n",
      "2  Less direct geological evidence indicates that...  \n",
      "3  Fossil fuel power plants cause the emission of...  \n",
      "4  Higher atmospheric CO2 concentrations have led...  \n"
     ]
    }
   ],
   "source": [
    "# 向训练数据集添加文本内容\n",
    "ml_training_df['claim_text'] = ml_training_df['claim_id'].apply(lambda x: claims_df.loc[claims_df['claim_id'] == x, 'claim_text'].values[0])\n",
    "ml_training_df['evidence_text'] = ml_training_df['evidence_id'].apply(lambda x: evidence_df.loc[evidence_df['evidence_id'] == x, 'text'].values[0])\n",
    "\n",
    "print(ml_training_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将训练和验证数据集保存为CSV文件\n",
    "ml_training_df.to_csv('data/ml_training_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average evidence count: 3.3566775244299674\n"
     ]
    }
   ],
   "source": [
    "# 计算train-claim中平均证据数量\n",
    "total_evidence_count = 0\n",
    "for index, row in claims_df.iterrows():\n",
    "    total_evidence_count += len(row['evidences'])\n",
    "average_evidence_count = total_evidence_count / len(claims_df)\n",
    "print(f\"Average evidence count: {average_evidence_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, claims, evidences, labels, vocab=None):\n",
    "        self.tokenizer = get_tokenizer(\"basic_english\")\n",
    "        self.claims = [self.tokenizer(claim) for claim in claims]\n",
    "        self.evidences = [self.tokenizer(evidence) for evidence in evidences]\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab if vocab else self.build_vocab(self.claims + self.evidences)\n",
    "        \n",
    "    def build_vocab(self, data):\n",
    "        counter = Counter()\n",
    "        for text in data:\n",
    "            counter.update(text)\n",
    "        return Vocab(counter, specials=['<unk>', '<pad>'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        claim = [self.vocab.stoi[word] for word in self.claims[idx]]\n",
    "        evidence = [self.vocab.stoi[word] for word in self.evidences[idx]]\n",
    "        return torch.tensor(claim), torch.tensor(evidence), torch.tensor(self.labels[idx])\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        claims, evidences, labels = zip(*batch)\n",
    "        claims_pad = nn.utils.rnn.pad_sequence(claims, padding_value=vocab.stoi['<pad>'])\n",
    "        evidences_pad = nn.utils.rnn.pad_sequence(evidences, padding_value=vocab.stoi['<pad>'])\n",
    "        return claims_pad, evidences_pad, torch.stack(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, claims, evidences):\n",
    "        embedded_claims = self.embedding(claims)\n",
    "        embedded_evidences = self.embedding(evidences)\n",
    "        lstm_out_claims, _ = self.lstm(embedded_claims)\n",
    "        lstm_out_evidences, _ = self.lstm(embedded_evidences)\n",
    "        combined_features = torch.cat((lstm_out_claims[:, -1, :], lstm_out_evidences[:, -1, :]), dim=1)\n",
    "        output = self.fc(combined_features)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割数据\n",
    "claims_train, claims_val, evidences_train, evidences_val, labels_train, labels_val = train_test_split(\n",
    "    ml_training_df['claim_text'], ml_training_df['evidence_text'], ml_training_df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建数据集\n",
    "train_dataset = TextDataset(claims_train, evidences_train, labels_train)\n",
    "val_dataset = TextDataset(claims_val, evidences_val, labels_val, vocab=train_dataset.vocab)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=TextDataset.collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=TextDataset.collate_fn)\n",
    "\n",
    "# 定义模型\n",
    "model = BiLSTM(len(train_dataset.vocab), embedding_dim=100, hidden_dim=128, output_dim=1)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "# 训练\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(10):  # 进行10个epoch的训练\n",
    "    model.train()\n",
    "    for claims, evidences, labels in train_loader:\n",
    "        if torch.cuda.is_available():\n",
    "            claims, evidences, labels = claims.cuda(), evidences.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(claims, evidences)\n",
    "        loss = criterion(outputs.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for claims, evidences, labels in val_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                claims, evidences, labels = claims.cuda(), evidences.cuda(), labels.cuda()\n",
    "            outputs = model(claims, evidences)\n",
    "            predictions = torch.round(torch.sigmoid(outputs.squeeze()))\n",
    "            all_preds.extend(predictions.tolist())\n",
    "            all_labels.extend(labels.tolist())\n",
    "\n",
    "# 输出报告\n",
    "print(classification_report(all_labels, all_preds))\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'data/bilstm_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  evidence_id                                               text  \\\n",
      "0  evidence-0  John Bennet Lawes English entrepreneur and agr...   \n",
      "1  evidence-1  Lindberg began his professional career at the ...   \n",
      "2  evidence-2      Boston Ladies of Cambridge by Vampire Weekend   \n",
      "3  evidence-3  Gerald Francis Goyer born October 20 1936 was ...   \n",
      "4  evidence-4  He detected abnormalities of oxytocinergic fun...   \n",
      "\n",
      "                                            entities  \\\n",
      "0                       [John Bennet Lawes, English]   \n",
      "1     [Lindberg, the age of 16, New York City, 1977]   \n",
      "2   [``Boston (Ladies of Cambridge, Vampire Weekend]   \n",
      "3  [Gerald Francis Goyer, October 20, 1936, 40, t...   \n",
      "4                                              [ECT]   \n",
      "\n",
      "                                              tokens  \n",
      "0  [john, bennet, lawes, english, entrepreneur, a...  \n",
      "1  [lindberg, begin, professional, career, age, 1...  \n",
      "2  [boston, ladies, cambridge, vampire, weekend, ...  \n",
      "3  [gerald, francis, goyer, bear, october, 20, 19...  \n",
      "4  [detect, abnormality, oxytocinergic, function,...  \n"
     ]
    }
   ],
   "source": [
    "print(evidence_df.head())\n",
    "# 保存证据数据\n",
    "evidence_df.to_csv('data/evidence_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
